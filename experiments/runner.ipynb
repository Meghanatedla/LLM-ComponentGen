{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Generation\n",
    "## Imports and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from CreatePrompt import CreatePrompt\n",
    "from LLMInterface import LLMInterface\n",
    "from Gemini import Gemini\n",
    "from OpenAIModel import OpenAIModel\n",
    "from CodeQwen import CodeQwen\n",
    "from ArtigenzCoder import ArtigenzCoder\n",
    "from DeepSeek import DeepSeek\n",
    "from LocalLLM import LocalLLM\n",
    "from CodebleuCalculator import codebleu_score_calculator, avg_codebleu_score_calculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Validating Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = input(\"Enter the path to the config file: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(config_file_path))\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_config(config: dict):\n",
    "    required_keys = [\n",
    "    \"language\", \"summarize_codebase\", \"codebase_readme_path\", \"files_to_summarize_paths\", \"codebase_summary_prompt_template\", \"codebase_summary_prompt_save_path\", \"codebase_summary_save_path\", \"function_description_prompt_template\", \"function_description_prompt_save_path\", \"function_description_save_path\",  \"function_generation_prompt_template_type1\", \"function_generation_prompt_type1_save_path\", \"function_generation_prompt_template_type2\", \"function_generation_prompt_type2_save_path\", \"function_generation_prompt_template_type3\", \"function_generation_prompt_type3_save_path\", \"chosen_function_path\", \"chosen_function\", \"original_function_save_path\", \"example_function_description1\", \"example_function_code1\", \"example_function_description2\", \"example_function_code2\", \"generated_function_type1_save_dir\", \"generated_function_type2_save_dir\", \"generated_function_type3_save_dir\", \"run_codebleu\", \"codebleu_type1_save_dir\", \"codebleu_type2_save_dir\", \"codebleu_type3_save_dir\"     \n",
    "    ]\n",
    "    \n",
    "    for key in required_keys:\n",
    "        if key not in config:\n",
    "            raise ValueError(f\"Missing required key: {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_config(config)\n",
    "print(\"Config validated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebase summarization prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summarization_prompt = CreatePrompt.create_summary_prompt(config['codebase_summary_prompt_template'], config['files_to_summarize_paths'], config['language'], config['codebase_summary_prompt_save_path'])\n",
    "except Exception as e:\n",
    "    print(f\"Error creating summarization prompt: {e}\")\n",
    "    \n",
    "print(\"Created summarization prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function description prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    function_description_prompt = CreatePrompt.create_func_description_prompt(config['function_description_prompt_template'], config['chosen_function_path'], config['language'], config['function_description_prompt_save_path'])\n",
    "except Exception as e:\n",
    "    print(f\"Error creating function description prompt: {e}\")\n",
    "\n",
    "print(\"Created function description prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read summarization and function description prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['codebase_summary_prompt_save_path'], 'r') as f:\n",
    "    summarization_prompt = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['function_description_prompt_save_path'], 'r') as f:\n",
    "    function_description_prompt = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize codebase and generate function description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = Gemini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebase_summary = gemini.generate(summarization_prompt)\n",
    "gemini.write_to_file(config['codebase_summary_save_path'])\n",
    "print(\"Summarized codebase\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_description = gemini.generate(function_description_prompt)\n",
    "gemini.write_to_file(config['function_description_save_path'])\n",
    "print(\"Generated function description\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config['original_function_save_path']):\n",
    "    shutil.copyfile(config['chosen_function_path'], config['original_function_save_path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Generation Type 1 Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_generation_prompt_type1 = CreatePrompt.create_func_generation_prompt_type1(\n",
    "                                    config['function_generation_prompt_template_type1'], \n",
    "                                    config['codebase_readme_path'], \n",
    "                                    config['function_description_save_path'], \n",
    "                                    config['function_generation_prompt_type1_save_path']\n",
    "                                    )\n",
    "print(\"Created function generation prompt type 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Generation Type 2 Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_generation_prompt_type2 = CreatePrompt.create_func_generation_prompt_type2(\n",
    "                                    config['function_generation_prompt_template_type2'], \n",
    "                                    config['codebase_summary_save_path'], \n",
    "                                    config['function_description_save_path'], \n",
    "                                    config['function_generation_prompt_type2_save_path']\n",
    "                                    )\n",
    "print(\"Created function generation prompt type 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Generation Type 3 Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"function_generation_prompt_type3_save_path\"] == \"\":\n",
    "    print(\"Skipping function generation prompt type 3\")\n",
    "else:    \n",
    "    example_functions = [[config['example_function_description1'], config['example_function_code1']], [config['example_function_description2'], config['example_function_code2']]]\n",
    "\n",
    "    function_generation_prompt_type3 = CreatePrompt.create_func_generation_prompt_type3(\n",
    "                                        config['function_generation_prompt_template_type3'], \n",
    "                                        config['codebase_summary_save_path'], \n",
    "                                        example_functions, \n",
    "                                        config['function_description_save_path'], \n",
    "                                        config['function_generation_prompt_type3_save_path']\n",
    "                                        )\n",
    "    print(\"Created function generation prompt type 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://userName-codeqwen1-5-7b-chat.hf.space ✔\n",
      "Loaded as API: https://userName-artigenz-artigenz-coder-ds-6-7b.hf.space ✔\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"GPT-3_5-Turbo\": OpenAIModel(\"gpt-3.5-turbo\"), \n",
    "    \"GPT-4\": OpenAIModel(\"gpt-4\"), \n",
    "    \"DeepSeek-Coder-V2\": DeepSeek(), \n",
    "    \"CodeQwen1_5-7B-Chat\": CodeQwen(), \n",
    "    \"Artigenz-Coder-DS-6_7B\": ArtigenzCoder()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_func_generation_prompts = False\n",
    "\n",
    "def load_func_generation_prompts(config):\n",
    "    with open(config['function_generation_prompt_type1_save_path'], 'r') as f:\n",
    "        function_generation_prompt_type1 = f.read()\n",
    "    \n",
    "    with open(config['function_generation_prompt_type2_save_path'], 'r') as f:\n",
    "        function_generation_prompt_type2 = f.read()\n",
    "\n",
    "    function_generation_prompt_type3 = \"\"\n",
    "    if config[\"function_generation_prompt_type3_save_path\"] != \"\":\n",
    "        with open(config['function_generation_prompt_type3_save_path'], 'r') as f:\n",
    "            function_generation_prompt_type3 = f.read()\n",
    "\n",
    "    return function_generation_prompt_type1, function_generation_prompt_type2, function_generation_prompt_type3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_generation_prompts = {\n",
    "    \"type1\": function_generation_prompt_type1,\n",
    "    \"type2\": function_generation_prompt_type2,\n",
    "    \"type3\": function_generation_prompt_type3\n",
    "}\n",
    "\n",
    "generated_function_save_dirs = {\n",
    "    \"type1\": config['generated_function_type1_save_dir'],\n",
    "    \"type2\": config['generated_function_type2_save_dir'],\n",
    "    \"type3\": config['generated_function_type3_save_dir']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"GPT-3_5-Turbo\", \"GPT-4\", \"DeepSeek-Coder-V2\", \"CodeQwen1_5-7B-Chat\", \"Artigenz-Coder-DS-6_7B\"]\n",
    "prompt_types = [\"type1\", \"type2\", \"type3\"]\n",
    "\n",
    "generated_function_save_paths = {t: {m: [] for m in model_names} for t in prompt_types}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt_type in [\"type1\", \"type2\", \"type3\"]:\n",
    "\n",
    "    if prompt_type == \"type3\" and config[\"generated_function_type3_save_dir\"] == \"\":\n",
    "        print(\"Skipping function generation prompt type 3\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Running prompt type {prompt_type}\")\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f\"Running {model_name} model\")\n",
    "\n",
    "        for i in range(1, generation_count + 1):\n",
    "\n",
    "            generated_function = model.generate(function_generation_prompts[prompt_type])\n",
    "\n",
    "            filename = config[\"chosen_function\"].split(\".\")\n",
    "            generated_function_save_filename = f\"{filename[0]}_{i}.{filename[1]}\"\n",
    "            generated_function_save_path = f\"{generated_function_save_dirs[prompt_type]}/{model_name}/GENERATED-{generated_function_save_filename}\"\n",
    "            model.write_to_file(generated_function_save_path)\n",
    "            \n",
    "            generated_function_save_paths[prompt_type][model_name].append(generated_function_save_path)\n",
    "            print(f\"Generated function {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeBlEU Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebleu_save_dirs = {\n",
    "    \"type1\": config['codebleu_type1_save_dir'],\n",
    "    \"type2\": config['codebleu_type2_save_dir'],\n",
    "    \"type3\": config['codebleu_type3_save_dir']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['run_codebley']:\n",
    "\n",
    "    for prompt_type in prompt_types:\n",
    "\n",
    "        if prompt_type == \"type3\" and config[\"codebleu_type3_save_dir\"] == \"\":\n",
    "            print(\"Skipping codebleu for prompt type 3\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Running codebleu for prompt {prompt_type}\")\n",
    "        for model_name , generated_function_paths in generated_function_save_paths[prompt_type].items():\n",
    "            \n",
    "            codebleu_scores = []\n",
    "            for i, generated_function_path in enumerate(generated_function_paths):\n",
    "                \n",
    "                codebleu_score = codebleu_score_calculator(\n",
    "                    config['original_function_save_path'],\n",
    "                    generated_function_path\n",
    "                )\n",
    "                codebleu_scores.append(codebleu_score)\n",
    "\n",
    "            avg_codebleu_score = avg_codebleu_score_calculator(codebleu_scores)\n",
    "            print(f\"Calculated codebleu score for {model_name}\\n\")\n",
    "\n",
    "            codebleu_save_path = f\"{codebleu_save_dirs[prompt_type]}/{model_name}.txt\"\n",
    "\n",
    "            os.makedirs(os.path.dirname(codebleu_save_path), exist_ok=True) \n",
    "            with open(codebleu_save_path, 'w') as f:\n",
    "                f.write(f\"CodeBLEU Result:\\n{avg_codebleu_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
