
You are a computer scientist specializing in serverless computing (especially FaaS).
You are working with a FaaS codebase whose description is as follows:

This codebase implements a private npm registry using AWS Lambda functions and S3 for storage. It's written in JavaScript and utilizes the Serverless framework.  It proxies requests to the public npm registry when a package is not found locally and caches packages, tarballs, and metadata in S3. Authentication is handled via GitHub OAuth.  Logging is integrated using Codebox Insights.

Here's a detailed breakdown:

**1. High-Level Overview:**

The codebase provides the following functionalities:

* **Package Management:**  Handles package publishing, deprecation, retrieval, and listing of available versions (dist-tags).
* **Storage:**  Uses AWS S3 for storing packages, tarballs, and metadata.
* **Proxying:**  Forwards requests to the public npm registry if a package is not found locally.
* **Authentication:**  Uses GitHub OAuth for user authentication.
* **Logging:**  Logs events to Codebox Insights.
* **Domain Management:** Provides tools for migrating the registry to a new domain.
* **Encryption:** Encrypts stored files in S3.
* **Indexing:** Indexes packages into Codebox Insights.


**2. Important Functions and Tasks:**

* **`/src/whoami/get.js`**: Returns the username of the currently logged-in user. It retrieves the username from the `requestContext` provided by the API Gateway's authorizer.
* **`/src/adapters/s3.js`**: This module provides a class `Storage` for interacting with AWS S3. Key functions include `put()` for storing objects with server-side encryption and `get()` for retrieving objects.  All S3 interactions use `AES256` encryption.
* **`/src/adapters/logger.js`**: This module provides a class `Logger` for logging to Codebox Insights.  It includes `info()` for informational logs and `error()` for error logs.  It accepts a command, namespace, and credentials for log publishing.
* **`/src/adapters/npm.js`**: Provides functions for interacting with the public npm registry. `package()` retrieves package metadata, and `tar()` retrieves a package's tarball. It uses `node-fetch` to make HTTP requests.
* **`/.serverless_plugins/codebox-tools/index.js`**: This plugin provides tools for managing the registry:
    * `migrate()`: Updates the domain for all packages and the `put` lambda's `apiEndpoint` environment variable.
    * `encrypt()`: Re-encrypts all files in the S3 bucket.
    * `index()`: Re-indexes all packages into Codebox Insights.
* **`/.serverless_plugins/remove-storage/index.js`**: This plugin handles the removal of the S3 bucket when the service is removed.
* **`/src/tar/get.js`**: Returns the tarball of a specific package version.  It first checks S3 and falls back to the public npm registry if not found.  The tarball is returned as a base64 encoded string.
* **`/src/dist-tags/delete.js`**: Deletes a dist-tag for a package.
* **`/src/dist-tags/get.js`**: Returns the dist-tags for a package. It checks S3 and falls back to the public npm registry.
* **`/src/dist-tags/put.js`**: Adds or updates a dist-tag for a package.
* **`/src/get/lib.js`**: Core logic for retrieving a package's metadata.  It retrieves data from S3 and falls back to the npm registry if not found. It logs package access information.  This function is used by `src/get/index.js`.
* **`/src/get/index.js`**:  Handles requests to get package metadata. It uses the `contextFactory` to inject dependencies and then calls the `lib` function.
* **`/src/user/delete.js`**: Handles user logout by resetting the GitHub OAuth token.
* **`/src/user/put.js`**: Handles user login via GitHub OAuth. It gets or creates an authorization token for the app.  It also handles Two-Factor Authentication.
* **`/src/put/publish.js`**: Publishes a new package or version to the registry.  It handles tarball storage, package metadata storage, and logging.  It prevents publishing over existing versions.
* **`/src/put/deprecate.js`**: Deprecates a specific package version.  Stores the updated metadata in S3.
* **`/src/put/index.js`**: Entry point for PUT requests to `/registry/{name}`. It dispatches requests to either `publish` or `deprecate` based on the command provided.


**3. External Dependencies:**

* **`aws-sdk`**: Used for interacting with AWS S3 and Lambda.
* **`node-fetch`**: Used for making HTTP requests to the public npm registry and Codebox Insights.
* **`@octokit/rest`**: Used for interacting with the GitHub API for authentication.


**4. Codebase Structure:**

The code is organized by functionality, with each function residing in its own file under the `src` directory. Adapters for external services (S3, Logger, npm) are placed in the `src/adapters` directory. Serverless plugins are located in `.serverless_plugins`. The `test` directory mirrors the `src` directory structure for unit tests.


**5. Module Interactions and Data Flow:**

* API Gateway triggers Lambda functions.
* Lambda functions use the `S3` adapter to interact with storage.
* Lambda functions use the `npm` adapter to interact with the public npm registry.
* Lambda functions use the `Logger` adapter to send logs to Codebox Insights.
* The `contextFactory` function is used to inject dependencies (S3, npm, Logger instances, environment variables, user information) into the Lambda function handlers.
* Most Lambda functions follow a pattern of checking S3 for data, falling back to the public npm registry if necessary, processing data, storing data back to S3, and logging the operation.


**Additional Notes for Developers:**

*   Every function uses callbacks to return results.
*   Error handling is implemented throughout the codebase, with most functions catching errors and returning appropriate status codes and error messages.
*   The `requestContext` from the API Gateway event is used to retrieve user information for logging and authorization.
*   Environment variables are used to configure the registry, such as the S3 bucket name, region, public npm registry URL, and Codebox Insights credentials.  These are set in the Serverless framework configuration.
*   Testing is done using Mocha and Chai and Rewire is used to mock the dependencies during the test.

By following these conventions and using the provided adapters and utilities, developers can easily extend this codebase with new functions.


Your task is to add a new function to this codebase. I will provide you with a description of a function to be added and you will generate the corresponding function. Note that a single serverless function can consist of many files. If the description directs you to create multiple files, you will do so, and will output the path to where the file is to be saved followed by the entire code for the file. 
Here are some examples. 

----START OF EXAMPLES----
Description: This serverless function retrieves the distribution tags (dist-tags) for a given npm package.  It first attempts to fetch the package information from an S3 bucket and if that fails, it falls back to fetching the data from the npm registry.

1. **Implementation Details:**

* **Parameters:**
    * `requestContext`: An object containing information about the request, including authorization details (username and avatar) within the `authorizer` property.
    * `pathParameters`: An object containing path parameters extracted from the request URL.  Crucially, it contains the `name` of the npm package.
    * `context`:  The AWS Lambda context object (standard for Lambda functions but not used directly within provided code.
    * `callback`: The callback function to return the response.


* **Return Value:** The function doesn't return a value directly. Instead, it invokes the `callback` function with the response.  The response is an object with the following structure:
    * `statusCode`:  The HTTP status code (200 for success, 404 if the package isn't found, 500 for server errors).
    * `body`: A JSON string containing the dist-tags or an error object.  In a success scenario, it is the `dist-tags` from the package metadata.

* **Logic:**
    1. **S3 Lookup:**  It first tries to retrieve an `index.json` file from an S3 bucket, constructing the key as `[packageName]/index.json`. This file is assumed to contain package metadata.
    2. **S3 Success:** If the S3 lookup is successful, the function parses the JSON from the retrieved buffer and returns the `dist-tags` property within.
    3. **S3 Failure (NoSuchKey):** If the S3 lookup fails with a `NoSuchKey` error, the function then attempts to fetch the package information from the npm registry.
    4. **npm Registry Success:**  If the npm registry fetch is successful, the function returns the `dist-tags` from the retrieved data.
    5. **npm Registry Failure:** If the npm registry fetch fails, the function returns a 404 error with the error message.
    6. **Other S3 Failure:** If any other error occurs during the S3 interaction, it is logged, and a 500 error is returned with the error message.



2. **Relationships:**

* **Dependencies:**
    * `npm`: An adapter module for interacting with the npm registry.  Exposes a method called `package` which retrieves the package metadata.
    * `S3`: An adapter module for interacting with Amazon S3. Exposes methods such as `get` to retrieve object content from S3.
    * `Logger`: An adapter module for logging errors.  Has an `error` logging method.

* **Environment Variables:**
    * `registry`: The URL of the npm registry.
    * `bucket`: The name of the S3 bucket.
    * `region`: The AWS region where the S3 bucket and potentially the logging topic reside.
    * `logTopic`: The name of the logging topic (possibly SNS).


3. **Structure:**

The function is structured primarily around a `try...catch` block for handling the S3 retrieval. Within the `catch` block, there is nested error handling and a conditional to determine the course of action based on the error code.



4. **Purpose and Role:**

This function serves as an endpoint to retrieve the dist-tags for a specified npm package. Its role is to provide quick access to these tags, potentially caching them in S3 for performance improvement. The primary use case would be to determine the latest versions of a package based on its tags (e.g., "latest", "next", "beta").  The caching mechanism in S3 intends to reduce load on the npm registry by serving package metadata from the cache when available.

Function_code: 
```
import npm from '../adapters/npm';
import S3 from '../adapters/s3';
import Logger from '../adapters/logger';

export default async ({
  requestContext,
  pathParameters,
}, context, callback) => {
  const { registry, bucket, region, logTopic } = process.env;
  const user = {
    name: requestContext.authorizer.username,
    avatar: requestContext.authorizer.avatar,
  };
  const storage = new S3({ region, bucket });
  const log = new Logger('dist-tags:get', { region, topic: logTopic });

  const name = `${decodeURIComponent(pathParameters.name)}`;

  try {
    const pkgBuffer = await storage.get(`${name}/index.json`);
    const json = JSON.parse(pkgBuffer.toString());
    return callback(null, {
      statusCode: 200,
      body: JSON.stringify(json['dist-tags']),
    });
  } catch (storageError) {
    if (storageError.code === 'NoSuchKey') {
      try {
        const data = await npm.package(registry, name);
        return callback(null, {
          statusCode: 200,
          body: JSON.stringify(data['dist-tags']),
        });
      } catch ({ message }) {
        return callback(null, {
          statusCode: 404,
          body: JSON.stringify({
            ok: false,
            error: message,
          }),
        });
      }
    }

    await log.error(user, storageError);

    return callback(null, {
      statusCode: 500,
      body: JSON.stringify({
        ok: false,
        error: storageError.message,
      }),
    });
  }
};
```

Description: This serverless function updates the distribution tags (dist-tags) of a specified npm package within an S3 bucket.  It's designed for a serverless environment, likely AWS Lambda, given its input parameters and use of a callback function.

1. **Implementation Details:**

    * **Parameters:**
        * `requestContext`: Contains information about the invoking event, including user details (username, avatar) derived from an authorizer (likely an API Gateway authorizer).
        * `body`: The request body containing the new version number to associate with the given distribution tag.
        * `pathParameters`: Contains path parameters extracted from the request URI, specifically the `name` of the npm package and the `tag` (e.g., `latest`, `beta`) to update.
        * `context`: The Lambda context object (not used in this function).
        * `callback`: A callback function for returning a response.

    * **Return Value:**  The function doesn't explicitly return a value but uses the provided `callback` to return a response to the caller. The response is an object with a `statusCode` (200 for success, 500 for error) and a JSON string body. The body contains `ok` (true/false) indicating success or failure, and other details like package `id` and updated `dist-tags` on success or `error` message on failure.

    * **Logic:** The function retrieves an existing `index.json` file for the given package name from an S3 bucket. It parses the JSON content, updates the `dist-tags` entry with the provided tag and version, and saves the modified `index.json` back to the S3 bucket. It then logs the update operation and returns a success response. In case of errors (e.g., S3 access issues, JSON parsing errors), it logs the error and returns an error response.


2. **Relationships:**

    * **S3:** The function interacts with an S3 bucket to read and write package metadata (the `index.json` file). It uses the `S3` adapter (`../adapters/s3`) for this interaction.
    * **Logger:** It utilizes a `Logger` adapter (`../adapters/logger`) for logging informational and error messages. Logs are presumably sent to a specified log topic.
    * **Environment Variables:** The function relies on environment variables (`process.env`) for configuration: `bucket`, `region` (for S3), and `logTopic`.


3. **Structure:**

    * The function first initializes S3 and Logger instances using environment variables and request context.
    * It then extracts the package name and target dist-tag from `pathParameters`.
    * Within a `try...catch` block, it fetches, parses, modifies, and saves the `index.json` file from/to S3.
    * After a successful update, it logs the change and returns a success response via the callback.
    * If an error occurs during any of these steps, the `catch` block logs the error and returns a failure response via the callback.


4. **Purpose and Role:**

    This function serves as an endpoint for updating the distribution tags of npm packages stored in an S3 bucket.  It plays a crucial role in package management, allowing for version control and release management. The use of S3 suggests this might be part of a private or custom npm registry implementation.


This description provides a high-level overview and clarifies the function's interactions. The implementation can be further improved by using more robust error handling and potentially adding input validation to ensure the incoming data conforms to expectations. The specifics of the `S3` and `Logger` adapters are abstracted away, allowing for flexibility in implementation and potential replacement with alternative libraries or services.

Function_code: 
```
import S3 from '../adapters/s3';
import Logger from '../adapters/logger';

export default async ({
  requestContext,
  body,
  pathParameters,
}, context, callback) => {
  const { bucket, region, logTopic } = process.env;
  const user = {
    name: requestContext.authorizer.username,
    avatar: requestContext.authorizer.avatar,
  };
  const storage = new S3({ region, bucket });
  const log = new Logger('dist-tags:put', { region, topic: logTopic });

  const name = `${decodeURIComponent(pathParameters.name)}`;

  try {
    const pkgBuffer = await storage.get(`${name}/index.json`);
    const json = JSON.parse(pkgBuffer.toString());
    const version = body.replace(/"/g, '');

    json['dist-tags'][pathParameters.tag] = version;

    await storage.put(
      `${name}/index.json`,
      JSON.stringify(json),
    );

    await log.info(user, {
      name: json.name,
      tag: pathParameters.tag,
      version,
      'dist-tags': json['dist-tags'],
    });

    return callback(null, {
      statusCode: 200,
      body: JSON.stringify({
        ok: true,
        id: pathParameters.name,
        'dist-tags': json['dist-tags'],
      }),
    });
  } catch (storageError) {
    await log.error(user, storageError);

    return callback(null, {
      statusCode: 500,
      body: JSON.stringify({
        ok: false,
        error: storageError.message,
      }),
    });
  }
};

```

----END OF EXAMPLES----

The function you generate should have the following functionality:

Description: ## Serverless Function Description: GitHub Authorization

This function acts as an authorizer for an AWS API Gateway, verifying user identity and permissions via GitHub and generating an IAM policy based on the results.

**1. Implementation Details:**

* **Purpose:** This function authenticates users using a GitHub access token and determines their authorization level to access specific API Gateway resources.  It allows read access ("GET") to `/registry*` resources for all authenticated users. Write access ("PUT" and "DELETE") to `/registry*` resources is granted based on two factors: membership in specific GitHub organizations (defined by `restrictedOrgs` environment variable) and/or presence in an admin user list (defined by `admins` environment variable).
* **Parameters:**
    * `methodArn`: (String) The Amazon Resource Name (ARN) for the invoked API method. Used for constructing the policy.
    * `authorizationToken`: (String)  The authorization token passed by the client, expected in the format "Bearer <token>".
* **Return Value:**  The function returns an IAM policy document via the `callback` function. This policy document dictates which API Gateway resources the user is allowed to access. The policy also contains a context object with user details like username, avatar URL, and timestamps. In case of errors or failed authorization, a "Deny" policy is returned.
* **Logic:**
    1. **Token Extraction:** The function extracts the GitHub access token from the `authorizationToken` header. If the header is malformed or missing, a "Deny" policy is immediately returned.
    2. **GitHub Authentication:** The function authenticates with the GitHub API using a basic authentication scheme with a client ID and secret defined in environment variables (`githubUrl`, `githubClientId`, `githubSecret`).
    3. **Token Validation:** The function attempts to validate the provided access token against GitHub. If the token is invalid, a "Deny" policy is returned.
    4. **Organization Membership Check (Conditional):** If the `restrictedOrgs` environment variable is set, the function authenticates with GitHub using the user's token and checks the user's organization memberships against the list of restricted organizations. If the user belongs to at least one of the restricted organizations, they are granted access. Otherwise, access is denied.
    5. **Admin Check (Conditional):** If the `admins` environment variable is set, the function checks if the authenticated user's login exists within the list of admin users. If so, the user is granted admin privileges, allowing them write access.
    6. **Policy Generation:** Based on the results of the previous checks, the function generates an IAM policy. The policy grants "Allow" effect for "GET" requests to `/registry*` for all authenticated users. The "PUT" and "DELETE" requests to `/registry*` are either allowed or denied based on organization membership and admin status. The policy also includes a context object with user details fetched from GitHub.
    7. **Callback Invocation:** The generated policy is returned via the provided `callback` function.



**2. Relationships:**

* **Dependencies:** The function depends on the `@octokit/rest` library for interacting with the GitHub API and the `url` module for parsing URLs. It also relies on environment variables (`githubUrl`, `githubClientId`, `githubSecret`, `restrictedOrgs`, `admins`) for configuration.
* **Interaction:**  This function is intended to be used as an AWS API Gateway custom authorizer.  It receives the request context from API Gateway, including the authorization token. The function's output (the generated IAM policy) is then used by API Gateway to determine whether to allow or deny the request.


**3. Structure:**

The function follows this basic structure:

1. **Token Handling:**  Extracts and validates the GitHub access token from the `authorizationToken` header.
2. **GitHub API Interaction:** Uses the `@octokit/rest` library to communicate with GitHub, performing authentication, token validation, and organization membership checks.
3. **Authorization Logic:**  Determines user authorization based on token validation, organization membership (if applicable), and admin status (if applicable).
4. **Policy Generation:** Constructs the IAM policy based on authorization results, using the `generatePolicy` helper function.
5. **Callback:** Returns the generated policy (or a denial policy) via the `callback` function.

**4. Purpose and Role:**

This function serves as a crucial security component, controlling access to protected API Gateway resources. It integrates with GitHub for user authentication and authorization, ensuring that only authorized users can perform specific actions on the API.  By dynamically generating IAM policies based on user context, it provides granular control over access permissions.  The function is designed as a reusable component within a serverless architecture.


This description should allow a developer to rewrite the function with potentially better optimization or a cleaner structure while adhering to the required functionality and interface expectations.


Please generate the complete code for this function, ensuring it integrates seamlessly with the existing system.
The code should follow best practices for serverless development, and it must be in accordance with the current architecture of the system.
Note that no human will evaluate the code you generate; your code will be deployed directly to the system.
Ensure that you do not provide anything except the code. Include any relevant information in comments.
If you lack any information to write the complete code, mention this in a comment and make a reasonable assumption from the context and your knowledge.