
You are a computer scientist specializing in serverless computing (especially FaaS).
You are working with a FaaS codebase whose description is as follows:

```
## Codebase Summary for craftship_codebox-npm

This codebase implements a private npm registry using AWS Lambda functions (Node.js) and S3 for storage. It leverages GitHub for authentication and authorization.

**1. High-Level Overview:**

The codebase provides functionalities for publishing, downloading, and managing npm packages within a private registry. It uses S3 to store package data and metadata, and Lambda functions to handle various API requests. GitHub integration provides secure access control.  Additionally, the codebase includes custom serverless plugins for maintenance tasks like data migration, encryption, and indexing.

**2. Breakdown of Important Functions:**

**Lambda Functions:**

* **`/src/whoami/get.js`**: Returns the username of the currently logged-in user.  It retrieves the username from the `requestContext` provided by the API Gateway authorizer.

* **`/src/tar/get.js`**: Retrieves the tarball of a specific package version. It first checks S3. If the tarball is not present, it fetches it from the configured upstream npm registry and returns it base64 encoded.

* **`/src/authorizers/github.js`**:  Authenticates users against GitHub. It verifies the provided GitHub token and generates an IAM policy that allows or denies access to specific API Gateway resources based on user roles (admin or regular user) and organization membership (if configured).

* **`/src/dist-tags/delete.js`**: Deletes a specific distribution tag from a package.  Retrieves package metadata from S3, removes the specified tag, updates the metadata in S3, and logs the action.

* **`/src/dist-tags/get.js`**: Retrieves the distribution tags for a specific package.  It checks for the package metadata in S3 and returns the tags. If the package is not found locally, it falls back to the upstream npm registry.

* **`/src/get/index.js`**: Retrieves the package metadata (package.json) for a specific package.  It uses `/src/get/lib.js` to perform the retrieval logic, which includes checking S3 and falling back to the upstream npm registry if needed.

* **`/src/get/lib.js`**: Contains the core logic for fetching package metadata. It checks S3 first, falls back to the upstream registry, and logs package access.


* **`/src/user/delete.js`**: Logs out the user by revoking their GitHub access token.


* **`/src/user/put.js`**:  Logs in the user using their GitHub credentials and generates a GitHub access token. Handles Two-Factor Authentication (2FA) as well.


* **`/src/put/publish.js`**: Publishes a new package or a new version of an existing package. It checks for name conflicts with the public registry, stores the tarball and updated metadata in S3, and logs the publishing event.


* **`/src/put/deprecate.js`**: Deprecates a specific version of a package. Stores the updated package metadata (including the deprecation message) in S3.


* **`/src/put/index.js`**: Handles `PUT` requests for packages, delegating to either `publish` or `deprecate` based on the command being executed.



**Serverless Plugins:**

* **`/.serverless_plugins/codebox-tools/index.js`**: This plugin provides tools for managing the private registry. It implements commands for:
    * **`domain`**: Updates the hosted domain for the registry.
    * **`encrypt`**: Re-encrypts all files within the S3 bucket.
    * **`index`**: Re-indexes all packages into Codebox Insights.

* **`/.serverless_plugins/remove-storage/index.js`**: This plugin deletes the S3 bucket and all its contents before service removal.


**3. External Dependencies:**

* **`aws-sdk`**: Used for interacting with AWS services, primarily S3 and Lambda.
* **`node-fetch`**: Used for making HTTP requests, specifically to the upstream npm registry and the Codebox logging service.
* **`@octokit/rest`**: Used for interacting with the GitHub API for authentication and authorization.



**4. Codebase Structure:**

The codebase is organized by functionality, with each Lambda function residing in its own directory under `src`.  Adapter modules (`s3.js`, `logger.js`, `npm.js`) provide abstractions for interacting with external services. The serverless plugins are located under `.serverless_plugins`. Test files are located in a separate `test` directory mimicking the `src` structure.

**5. Module Interactions & Data Flow:**

* **Lambda functions:** invoked by API Gateway requests, often using path parameters to determine the operation and the package name.

* **`S3` adapter:**  used by Lambda functions to store and retrieve package data (tarballs, metadata).

* **`npm` adapter:**  used by Lambda functions to interact with the upstream npm registry, primarily for fetching package information when it is not available in the private registry.

* **`logger` adapter:**  used to log events to the Codebox logging service.

* **GitHub API:** used by the authorizer and user management functions for authentication, authorization, and managing user tokens.

* **Serverless plugins:** interact with AWS services (S3, Lambda) to perform maintenance tasks.


**Practices/Styles:**

* ES6 modules are used throughout the codebase.
* Async/await is heavily used for asynchronous operations.
*  The `contextFactory.js` file provides a consistent way to create and pass context objects to Lambda functions, which contain commonly needed objects and parameters.
*  All functions expect event, context, and callback as parameters.
*  Base64 encoding is used for storing and transferring tarballs.


This detailed summary should allow developers to implement new functions and understand the relationships between different modules within the `craftship_codebox-npm` codebase without having to examine the original source files extensively.


```

Your task is to add a new function to this codebase. I will provide you with a description of a function to be added and you will generate the corresponding function. Note that a single serverless function can consist of many files. If the description directs you to create multiple files, you will do so, and will output the path to where the file is to be saved followed by the entire code for the file. 
Here are some examples. 

----START OF EXAMPLES----
Description: ## Serverless Function Description: GitHub Authorization

This function acts as an authorizer for an AWS API Gateway, verifying user identity and permissions via GitHub and generating an IAM policy based on the results.

**1. Implementation Details:**

* **Purpose:** This function authenticates users using a GitHub access token and determines their authorization level to access specific API Gateway resources.  It allows read access ("GET") to `/registry*` resources for all authenticated users. Write access ("PUT" and "DELETE") to `/registry*` resources is granted based on two factors: membership in specific GitHub organizations (defined by `restrictedOrgs` environment variable) and/or presence in an admin user list (defined by `admins` environment variable).
* **Parameters:**
    * `methodArn`: (String) The Amazon Resource Name (ARN) for the invoked API method. Used for constructing the policy.
    * `authorizationToken`: (String)  The authorization token passed by the client, expected in the format "Bearer <token>".
* **Return Value:**  The function returns an IAM policy document via the `callback` function. This policy document dictates which API Gateway resources the user is allowed to access. The policy also contains a context object with user details like username, avatar URL, and timestamps. In case of errors or failed authorization, a "Deny" policy is returned.
* **Logic:**
    1. **Token Extraction:** The function extracts the GitHub access token from the `authorizationToken` header. If the header is malformed or missing, a "Deny" policy is immediately returned.
    2. **GitHub Authentication:** The function authenticates with the GitHub API using a basic authentication scheme with a client ID and secret defined in environment variables (`githubUrl`, `githubClientId`, `githubSecret`).
    3. **Token Validation:** The function attempts to validate the provided access token against GitHub. If the token is invalid, a "Deny" policy is returned.
    4. **Organization Membership Check (Conditional):** If the `restrictedOrgs` environment variable is set, the function authenticates with GitHub using the user's token and checks the user's organization memberships against the list of restricted organizations. If the user belongs to at least one of the restricted organizations, they are granted access. Otherwise, access is denied.
    5. **Admin Check (Conditional):** If the `admins` environment variable is set, the function checks if the authenticated user's login exists within the list of admin users. If so, the user is granted admin privileges, allowing them write access.
    6. **Policy Generation:** Based on the results of the previous checks, the function generates an IAM policy. The policy grants "Allow" effect for "GET" requests to `/registry*` for all authenticated users. The "PUT" and "DELETE" requests to `/registry*` are either allowed or denied based on organization membership and admin status. The policy also includes a context object with user details fetched from GitHub.
    7. **Callback Invocation:** The generated policy is returned via the provided `callback` function.



**2. Relationships:**

* **Dependencies:** The function depends on the `@octokit/rest` library for interacting with the GitHub API and the `url` module for parsing URLs. It also relies on environment variables (`githubUrl`, `githubClientId`, `githubSecret`, `restrictedOrgs`, `admins`) for configuration.
* **Interaction:**  This function is intended to be used as an AWS API Gateway custom authorizer.  It receives the request context from API Gateway, including the authorization token. The function's output (the generated IAM policy) is then used by API Gateway to determine whether to allow or deny the request.


**3. Structure:**

The function follows this basic structure:

1. **Token Handling:**  Extracts and validates the GitHub access token from the `authorizationToken` header.
2. **GitHub API Interaction:** Uses the `@octokit/rest` library to communicate with GitHub, performing authentication, token validation, and organization membership checks.
3. **Authorization Logic:**  Determines user authorization based on token validation, organization membership (if applicable), and admin status (if applicable).
4. **Policy Generation:** Constructs the IAM policy based on authorization results, using the `generatePolicy` helper function.
5. **Callback:** Returns the generated policy (or a denial policy) via the `callback` function.

**4. Purpose and Role:**

This function serves as a crucial security component, controlling access to protected API Gateway resources. It integrates with GitHub for user authentication and authorization, ensuring that only authorized users can perform specific actions on the API.  By dynamically generating IAM policies based on user context, it provides granular control over access permissions.  The function is designed as a reusable component within a serverless architecture.


This description should allow a developer to rewrite the function with potentially better optimization or a cleaner structure while adhering to the required functionality and interface expectations.

Function_code: 
```
import url from 'url';
import GitHub from '@octokit/rest';

const generatePolicy = ({
  effect,
  methodArn,
  token,
  isAdmin,
}) => {
  const methodParts = methodArn.split(':');
  const region = methodParts[3];
  const accountArn = methodParts[4];
  const apiId = methodParts[5].split('/')[0];
  const stage = methodParts[5].split('/')[1];

  const authResponse = {};
  authResponse.principalId = token;

  const policyDocument = {};
  policyDocument.Version = '2012-10-17';
  policyDocument.Statement = [];

  const statementOne = {};
  statementOne.Action = 'execute-api:Invoke';
  statementOne.Effect = effect;
  statementOne.Resource = `arn:aws:execute-api:${region}:${accountArn}:${apiId}/${stage}/GET/registry*`;
  policyDocument.Statement[0] = statementOne;

  const statementTwo = {};
  statementTwo.Action = 'execute-api:Invoke';
  statementTwo.Effect = isAdmin ? 'Allow' : 'Deny';
  statementTwo.Resource = `arn:aws:execute-api:${region}:${accountArn}:${apiId}/${stage}/PUT/registry*`;
  policyDocument.Statement[1] = statementTwo;

  const statementThree = {};
  statementThree.Action = 'execute-api:Invoke';
  statementThree.Effect = isAdmin ? 'Allow' : 'Deny';
  statementThree.Resource = `arn:aws:execute-api:${region}:${accountArn}:${apiId}/${stage}/DELETE/registry*`;
  policyDocument.Statement[2] = statementThree;

  authResponse.policyDocument = policyDocument;

  return authResponse;
};

export default async ({ methodArn, authorizationToken }, context, callback) => {
  const tokenParts = authorizationToken.split('Bearer ');

  if (tokenParts.length <= 1) {
    return callback(null, generatePolicy({
      token: authorizationToken,
      effect: 'Deny',
      methodArn,
      isAdmin: false,
    }));
  }

  const token = tokenParts[1];

  const parsedUrl = url.parse(process.env.githubUrl);
  const github = new GitHub({
    host: parsedUrl.host,
    protocol: 'https',
    pathPrefix: parsedUrl.path,
  });

  github.authenticate({
    type: 'basic',
    username: process.env.githubClientId,
    password: process.env.githubSecret,
  });

  try {
    const {
      user,
      updated_at,
      created_at,
    } = await github.authorization.check({
      client_id: process.env.githubClientId,
      access_token: token,
    });

    let isAdmin = false;
    let effect = 'Allow';
    let restrictedOrgs = [];

    if (process.env.restrictedOrgs) {
      restrictedOrgs = process.env.restrictedOrgs.split(',');
    }

    if (restrictedOrgs.length) {
      try {
        github.authenticate({
          type: 'token',
          token,
        });

        const orgs = await github.users.getOrgMemberships({
          state: 'active',
        });

        const usersOrgs = orgs.filter(org => restrictedOrgs.indexOf(org.organization.login) > -1);
        effect = usersOrgs.length ? 'Allow' : 'Deny';
      } catch (githubError) {
        return callback(null, generatePolicy({
          token: tokenParts[1],
          effect: 'Deny',
          methodArn,
          isAdmin: false,
        }));
      }
    }

    if (process.env.admins) {
      isAdmin = process.env.admins.split(',').indexOf(user.login) > -1;
    }

    const policy = generatePolicy({
      effect,
      methodArn,
      token,
      isAdmin,
    });

    policy.context = {
      username: user.login,
      avatar: user.avatar_url,
      updatedAt: updated_at,
      createdAt: created_at,
    };

    return callback(null, policy);
  } catch (error) {
    return callback(null, generatePolicy({
      token: tokenParts[1],
      effect: 'Deny',
      methodArn,
      isAdmin: false,
    }));
  }
};

```

Description: This serverless function retrieves the distribution tags (dist-tags) for a given npm package.  It first attempts to fetch the package information from an S3 bucket and if that fails, it falls back to fetching the data from the npm registry.

1. **Implementation Details:**

* **Parameters:**
    * `requestContext`: An object containing information about the request, including authorization details (username and avatar) within the `authorizer` property.
    * `pathParameters`: An object containing path parameters extracted from the request URL.  Crucially, it contains the `name` of the npm package.
    * `context`:  The AWS Lambda context object (standard for Lambda functions but not used directly within provided code.
    * `callback`: The callback function to return the response.


* **Return Value:** The function doesn't return a value directly. Instead, it invokes the `callback` function with the response.  The response is an object with the following structure:
    * `statusCode`:  The HTTP status code (200 for success, 404 if the package isn't found, 500 for server errors).
    * `body`: A JSON string containing the dist-tags or an error object.  In a success scenario, it is the `dist-tags` from the package metadata.

* **Logic:**
    1. **S3 Lookup:**  It first tries to retrieve an `index.json` file from an S3 bucket, constructing the key as `[packageName]/index.json`. This file is assumed to contain package metadata.
    2. **S3 Success:** If the S3 lookup is successful, the function parses the JSON from the retrieved buffer and returns the `dist-tags` property within.
    3. **S3 Failure (NoSuchKey):** If the S3 lookup fails with a `NoSuchKey` error, the function then attempts to fetch the package information from the npm registry.
    4. **npm Registry Success:**  If the npm registry fetch is successful, the function returns the `dist-tags` from the retrieved data.
    5. **npm Registry Failure:** If the npm registry fetch fails, the function returns a 404 error with the error message.
    6. **Other S3 Failure:** If any other error occurs during the S3 interaction, it is logged, and a 500 error is returned with the error message.



2. **Relationships:**

* **Dependencies:**
    * `npm`: An adapter module for interacting with the npm registry.  Exposes a method called `package` which retrieves the package metadata.
    * `S3`: An adapter module for interacting with Amazon S3. Exposes methods such as `get` to retrieve object content from S3.
    * `Logger`: An adapter module for logging errors.  Has an `error` logging method.

* **Environment Variables:**
    * `registry`: The URL of the npm registry.
    * `bucket`: The name of the S3 bucket.
    * `region`: The AWS region where the S3 bucket and potentially the logging topic reside.
    * `logTopic`: The name of the logging topic (possibly SNS).


3. **Structure:**

The function is structured primarily around a `try...catch` block for handling the S3 retrieval. Within the `catch` block, there is nested error handling and a conditional to determine the course of action based on the error code.



4. **Purpose and Role:**

This function serves as an endpoint to retrieve the dist-tags for a specified npm package. Its role is to provide quick access to these tags, potentially caching them in S3 for performance improvement. The primary use case would be to determine the latest versions of a package based on its tags (e.g., "latest", "next", "beta").  The caching mechanism in S3 intends to reduce load on the npm registry by serving package metadata from the cache when available.

Function_code: 
```
import npm from '../adapters/npm';
import S3 from '../adapters/s3';
import Logger from '../adapters/logger';

export default async ({
  requestContext,
  pathParameters,
}, context, callback) => {
  const { registry, bucket, region, logTopic } = process.env;
  const user = {
    name: requestContext.authorizer.username,
    avatar: requestContext.authorizer.avatar,
  };
  const storage = new S3({ region, bucket });
  const log = new Logger('dist-tags:get', { region, topic: logTopic });

  const name = `${decodeURIComponent(pathParameters.name)}`;

  try {
    const pkgBuffer = await storage.get(`${name}/index.json`);
    const json = JSON.parse(pkgBuffer.toString());
    return callback(null, {
      statusCode: 200,
      body: JSON.stringify(json['dist-tags']),
    });
  } catch (storageError) {
    if (storageError.code === 'NoSuchKey') {
      try {
        const data = await npm.package(registry, name);
        return callback(null, {
          statusCode: 200,
          body: JSON.stringify(data['dist-tags']),
        });
      } catch ({ message }) {
        return callback(null, {
          statusCode: 404,
          body: JSON.stringify({
            ok: false,
            error: message,
          }),
        });
      }
    }

    await log.error(user, storageError);

    return callback(null, {
      statusCode: 500,
      body: JSON.stringify({
        ok: false,
        error: storageError.message,
      }),
    });
  }
};
```

----END OF EXAMPLES----

The function you generate should have the following functionality:

Description: This serverless function updates the distribution tags (dist-tags) of a specified npm package within an S3 bucket.  It's designed for a serverless environment, likely AWS Lambda, given its input parameters and use of a callback function.

1. **Implementation Details:**

    * **Parameters:**
        * `requestContext`: Contains information about the invoking event, including user details (username, avatar) derived from an authorizer (likely an API Gateway authorizer).
        * `body`: The request body containing the new version number to associate with the given distribution tag.
        * `pathParameters`: Contains path parameters extracted from the request URI, specifically the `name` of the npm package and the `tag` (e.g., `latest`, `beta`) to update.
        * `context`: The Lambda context object (not used in this function).
        * `callback`: A callback function for returning a response.

    * **Return Value:**  The function doesn't explicitly return a value but uses the provided `callback` to return a response to the caller. The response is an object with a `statusCode` (200 for success, 500 for error) and a JSON string body. The body contains `ok` (true/false) indicating success or failure, and other details like package `id` and updated `dist-tags` on success or `error` message on failure.

    * **Logic:** The function retrieves an existing `index.json` file for the given package name from an S3 bucket. It parses the JSON content, updates the `dist-tags` entry with the provided tag and version, and saves the modified `index.json` back to the S3 bucket. It then logs the update operation and returns a success response. In case of errors (e.g., S3 access issues, JSON parsing errors), it logs the error and returns an error response.


2. **Relationships:**

    * **S3:** The function interacts with an S3 bucket to read and write package metadata (the `index.json` file). It uses the `S3` adapter (`../adapters/s3`) for this interaction.
    * **Logger:** It utilizes a `Logger` adapter (`../adapters/logger`) for logging informational and error messages. Logs are presumably sent to a specified log topic.
    * **Environment Variables:** The function relies on environment variables (`process.env`) for configuration: `bucket`, `region` (for S3), and `logTopic`.


3. **Structure:**

    * The function first initializes S3 and Logger instances using environment variables and request context.
    * It then extracts the package name and target dist-tag from `pathParameters`.
    * Within a `try...catch` block, it fetches, parses, modifies, and saves the `index.json` file from/to S3.
    * After a successful update, it logs the change and returns a success response via the callback.
    * If an error occurs during any of these steps, the `catch` block logs the error and returns a failure response via the callback.


4. **Purpose and Role:**

    This function serves as an endpoint for updating the distribution tags of npm packages stored in an S3 bucket.  It plays a crucial role in package management, allowing for version control and release management. The use of S3 suggests this might be part of a private or custom npm registry implementation.


This description provides a high-level overview and clarifies the function's interactions. The implementation can be further improved by using more robust error handling and potentially adding input validation to ensure the incoming data conforms to expectations. The specifics of the `S3` and `Logger` adapters are abstracted away, allowing for flexibility in implementation and potential replacement with alternative libraries or services.


Please generate the complete code for this function, ensuring it integrates seamlessly with the existing system.
The code should follow best practices for serverless development, and it must be in accordance with the current architecture of the system.
Note that no human will evaluate the code you generate; your code will be deployed directly to the system.
Ensure that you do not provide anything except the code. Include any relevant information in comments.
If you lack any information to write the complete code, mention this in a comment and make a reasonable assumption from the context and your knowledge.